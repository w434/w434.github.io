<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>计算机视觉 22 Image Generation | w434's blog</title><meta name="author" content="w434"><meta name="copyright" content="w434"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="自回归模型(Autoregressive Models)显式概率密度估计(Explicit Density Estimation: Autoregressive Models) 目标：得到显式函数p(x) &#x3D; f(x,W)  给定数据集x(1),x(2),…,x(n)，通过极大似然估计来训练模型：     Autoregressive Models： 假设每个 x 由多个子部分(维度)组">
<meta property="og:type" content="article">
<meta property="og:title" content="计算机视觉 22 Image Generation">
<meta property="og:url" content="http://example.com/post/e0e02130.html">
<meta property="og:site_name" content="w434&#39;s blog">
<meta property="og:description" content="自回归模型(Autoregressive Models)显式概率密度估计(Explicit Density Estimation: Autoregressive Models) 目标：得到显式函数p(x) &#x3D; f(x,W)  给定数据集x(1),x(2),…,x(n)，通过极大似然估计来训练模型：     Autoregressive Models： 假设每个 x 由多个子部分(维度)组">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg">
<meta property="article:published_time" content="2025-02-14T11:06:00.000Z">
<meta property="article:modified_time" content="2025-02-14T13:47:03.102Z">
<meta property="article:author" content="w434">
<meta property="article:tag" content="计算机视觉">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/post/e0e02130.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '计算机视觉 22 Image Generation',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-02-14 21:47:03'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2024/07/16/lsEXfWtGT6eRu7k.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">88</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">30</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/notes/"><i class="fa-fw fa-solid fa-school"></i><span> 课程笔记</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-face-smile"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/matches/"><i class="fa-fw fa-solid fa-futbol"></i><span> 足球赛事</span></a></li><li><a class="site-page child" href="/chess/"><i class="fa-fw fa-solid fa-chess"></i><span> 国际象棋</span></a></li><li><a class="site-page child" href="/comments/"><i class="fa-fw fa-solid fa-film"></i><span> 影评&amp;演出评论&amp;书评</span></a></li><li><a class="site-page child" href="/jottings/"><i class="fa-fw fa-solid fa-book"></i><span> 随笔</span></a></li><li><a class="site-page child" href="/varietyShow/"><i class="fa-fw fa-solid fa-tv"></i><span> 综艺</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fa-solid fa-gamepad"></i><span> 游戏</span></a></li><li><a class="site-page child" href="/musics/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="w434's blog"><span class="site-name">w434's blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/notes/"><i class="fa-fw fa-solid fa-school"></i><span> 课程笔记</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-face-smile"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/matches/"><i class="fa-fw fa-solid fa-futbol"></i><span> 足球赛事</span></a></li><li><a class="site-page child" href="/chess/"><i class="fa-fw fa-solid fa-chess"></i><span> 国际象棋</span></a></li><li><a class="site-page child" href="/comments/"><i class="fa-fw fa-solid fa-film"></i><span> 影评&amp;演出评论&amp;书评</span></a></li><li><a class="site-page child" href="/jottings/"><i class="fa-fw fa-solid fa-book"></i><span> 随笔</span></a></li><li><a class="site-page child" href="/varietyShow/"><i class="fa-fw fa-solid fa-tv"></i><span> 综艺</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fa-solid fa-gamepad"></i><span> 游戏</span></a></li><li><a class="site-page child" href="/musics/"><i class="fa-fw fa-solid fa-music"></i><span> 音乐</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">计算机视觉 22 Image Generation</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-02-14T11:06:00.000Z" title="Created 2025-02-14 19:06:00">2025-02-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-02-14T13:47:03.102Z" title="Updated 2025-02-14 21:47:03">2025-02-14</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="计算机视觉 22 Image Generation"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="自回归模型-Autoregressive-Models"><a href="#自回归模型-Autoregressive-Models" class="headerlink" title="自回归模型(Autoregressive Models)"></a>自回归模型(Autoregressive Models)</h1><h2 id="显式概率密度估计-Explicit-Density-Estimation-Autoregressive-Models"><a href="#显式概率密度估计-Explicit-Density-Estimation-Autoregressive-Models" class="headerlink" title="显式概率密度估计(Explicit Density Estimation: Autoregressive Models)"></a>显式概率密度估计(Explicit Density Estimation: Autoregressive Models)</h2><ul>
<li><p>目标：得到显式函数p(x) &#x3D; f(x,W)</p>
</li>
<li><p>给定数据集x(1),x(2),…,x(n)，通过极大似然估计来训练模型：</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/RZe4wrbczi6ftU8.png" alt="image.png"></p>
<ul>
<li>Autoregressive Models：<ol>
<li>假设每个 x 由多个子部分(维度)组成：x&#x3D;(x1，x2，…，xT)</li>
<li>使用链式法则分解概率表达式：<br>  <img src="https://s2.loli.net/2025/02/14/DpIBUNkO3erljvH.png" alt="image.png"></li>
<li>通过将上述方程代入损失函数来求 W∗。给定历史作为已知条件来预测下一个</li>
</ol>
</li>
</ul>
<h2 id="PixelCNN-and-PixelRNN"><a href="#PixelCNN-and-PixelRNN" class="headerlink" title="PixelCNN and PixelRNN"></a>PixelCNN and PixelRNN</h2><ul>
<li><p>从左上角开始，一次生成一个图像像素，逐像素生成</p>
</li>
<li><p>使用 RNN或CNN计算每个像素的概率，该概率取决于状态和从左侧和上方的 RGB值：</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/U7lDf2NKgL81YWn.png" alt="image.png"></p>
<ul>
<li>在每个像素处，预测红色，然后预测蓝色，然后预测绿色：softmax到[0，1，…，255]</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/tQLpCcMJalVPodf.png" alt="image.png"></p>
<h2 id="Generative-Pretraining-from-Pixels"><a href="#Generative-Pretraining-from-Pixels" class="headerlink" title="Generative Pretraining from Pixels"></a>Generative Pretraining from Pixels</h2><ul>
<li>使用自回归模型的Transformer:</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/yuZWfMGAloqbmUv.png" alt="image.png"></p>
<h1 id="变分自编码器-Variational-Autoencoder"><a href="#变分自编码器-Variational-Autoencoder" class="headerlink" title="变分自编码器(Variational Autoencoder)"></a>变分自编码器(Variational Autoencoder)</h1><h2 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h2><ul>
<li><p>Autoencoder：编码器压缩数据(CNN,降采样)，解码器重构数据(上采样);通常用于未标记数据的降维</p>
</li>
<li><p>编码器 e 和解码器 d 通常是神经网络</p>
</li>
<li><p>PCA 是一种线性自动编码器：</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/Uzs8CZH5twMIbgR.png" alt="image.png"></p>
<ul>
<li>其中，损失函数ε可以是 L2 损失或交叉熵损失。希望能够恢复原状，和x进行比较</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/v8RwmYnpLaQ25JK.png" alt="image.png"></p>
<ul>
<li>Autoencoder(黄)相比于PCA(蓝)更结构化，效果更好</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/DsU23I6cqXGMeiA.png" alt="image.png"></p>
<h2 id="Autoencoder-is-not-a-Generative-Model"><a href="#Autoencoder-is-not-a-Generative-Model" class="headerlink" title="Autoencoder is not a Generative Model"></a>Autoencoder is not a Generative Model</h2><ul>
<li>如果没有适当的正则化，来自潜在空间的样本可能毫无意义。由于其对隐空间无约束，所以若不是词典内的输入，可能导致不合理输出(位于中间地带)</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/E2TU3nZAJkDhYQs.png" alt="image.png"></p>
<ul>
<li><p>Reparameterization trick: 𝒛 &#x3D; 𝝁𝒙 + 𝝈𝒙 ∗ 𝜹, where 𝜹~𝑵(𝟎,𝟏)，采样不可微而z可微</p>
</li>
<li><p>经过Reparameterization trick后预测不是点而是预测分布，使得隐空间的区域都有一定覆盖，可以重建出过渡体</p>
</li>
<li><p>𝜹是噪音，可能导致坍缩，且隐空间中间缝隙会增大，所以需要进行KL loss正则化使得𝝁𝒙&#x3D;0，σx&#x3D;1靠拢：</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/JgIvsjdxSZae8Ep.png" alt="image.png"></p>
<ul>
<li>变分自动编码器：自动编码器 + 潜在空间具有良好的特性，可以实现生成过程</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/Gj2vUks5m3goKl1.png" alt="image.png"></p>
<h1 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network(GAN)"></a>Generative Adversarial Network(GAN)</h1><ul>
<li>随机数发生器(Generate uniform random numbers)，线性同余：</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/o19q7NHFRLPDQEM.png" alt="image.png"></p>
<ul>
<li>其他分布：𝑋 &#x3D; 𝐹^−1 (U)，其中F(X)是X的累积分布</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/kEBM4qxg1uvUVCw.png" alt="image.png"></p>
<ul>
<li><p>GAN:用神经网络拟合F(X)反函数：</p>
<ol>
<li>G是生成器：生成样本X和真实样本X(g)尽可能一样，用神经网络完成</li>
<li>D是判别器：通过二分类使X置为0，X(g)置为1</li>
<li>训练G和D直到判别器的正确率均为1&#x2F;2说明已经分别不出来生成的X和真实的X(g)(平衡位置)</li>
</ol>
</li>
<li><p>如果 P（Xg） 已知，则计算 F^−1（x）。但是它是未知的，只有来自此分布的一些样本</p>
</li>
<li><p>GAN:</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.model = nn.Sequential(</span><br><span class="line">            nn.Linear(input_dim, <span class="number">128</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, output_dim),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.model(z)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.model = nn.Sequential(</span><br><span class="line">            nn.Linear(input_dim, <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.model(x)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">z_dim = <span class="number">100</span>  <span class="comment"># 潜在空间的维度</span></span><br><span class="line">image_dim = <span class="number">784</span>  <span class="comment"># MNIST图像的维度（28x28）</span></span><br><span class="line"></span><br><span class="line">generator = Generator(z_dim, image_dim).to(device)</span><br><span class="line">discriminator = Discriminator(image_dim).to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">optimizer_g = optim.Adam(generator.parameters(), lr=<span class="number">0.0002</span>, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">optimizer_d = optim.Adam(discriminator.parameters(), lr=<span class="number">0.0002</span>, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (real_images, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        real_images = real_images.view(-<span class="number">1</span>, image_dim).to(device)</span><br><span class="line">        batch_size = real_images.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 标签</span></span><br><span class="line">        real_labels = torch.ones(batch_size, <span class="number">1</span>).to(device)</span><br><span class="line">        fake_labels = torch.zeros(batch_size, <span class="number">1</span>).to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练判别器</span></span><br><span class="line">        optimizer_d.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 真实图像</span></span><br><span class="line">        outputs = discriminator(real_images)</span><br><span class="line">        d_loss_real = criterion(outputs, real_labels)</span><br><span class="line">        d_loss_real.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成假图像</span></span><br><span class="line">        z = torch.randn(batch_size, z_dim).to(device)</span><br><span class="line">        fake_images = generator(z)</span><br><span class="line">        outputs = discriminator(fake_images.detach())</span><br><span class="line">        d_loss_fake = criterion(outputs, fake_labels)</span><br><span class="line">        d_loss_fake.backward()</span><br><span class="line"></span><br><span class="line">        d_loss = d_loss_real + d_loss_fake</span><br><span class="line">        optimizer_d.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练生成器</span></span><br><span class="line">        optimizer_g.zero_grad()</span><br><span class="line">        outputs = discriminator(fake_images)</span><br><span class="line">        g_loss = criterion(outputs, real_labels)</span><br><span class="line">        g_loss.backward()</span><br><span class="line">        optimizer_g.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], d_loss: <span class="subst">&#123;d_loss.item()&#125;</span>, g_loss: <span class="subst">&#123;g_loss.item()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">z = torch.randn(<span class="number">64</span>, z_dim).to(device)</span><br><span class="line">fake_images = generator(z)</span><br><span class="line">fake_images = fake_images.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">fake_images = fake_images.cpu().detach().numpy()</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">8</span>, <span class="number">8</span>, figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> i, ax <span class="keyword">in</span> <span class="built_in">enumerate</span>(axes.flatten()):</span><br><span class="line">    ax.imshow(fake_images[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2025/02/14/8gmPArNZ9VHzXU4.png" alt="image.png"></p>
<h2 id="The-Generator-of-DCGAN"><a href="#The-Generator-of-DCGAN" class="headerlink" title="The Generator of DCGAN"></a>The Generator of DCGAN</h2><p><img src="https://s2.loli.net/2025/02/14/5DXiCNyEaI1vMj8.png" alt="image.png"></p>
<p><img src="https://s2.loli.net/2025/02/14/y4G93iaPUCrt6fj.png" alt="image.png"></p>
<h2 id="StyleGAN"><a href="#StyleGAN" class="headerlink" title="StyleGAN"></a>StyleGAN</h2><p><img src="https://s2.loli.net/2025/02/14/BlDJQFhRtynjq2m.png" alt="image.png"></p>
<h1 id="Diffusion-Models"><a href="#Diffusion-Models" class="headerlink" title="Diffusion Models"></a>Diffusion Models</h1><ul>
<li>Diffusion Models通过前向过程和逆向过程来制造仿真：<ol>
<li>前向过程：逐渐添加噪声，直到得到高斯噪声</li>
<li>逆向过程：逐渐去除噪点，直到我们得到干净的图像</li>
</ol>
</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/v6AJpug3LCQEU74.png" alt="image.png"></p>
<p><img src="https://s2.loli.net/2025/02/14/2Dlo4CfENRmiYGF.png" alt="image.png"></p>
<h2 id="Forward-Process"><a href="#Forward-Process" class="headerlink" title="Forward Process"></a>Forward Process</h2><ul>
<li>马尔可夫链，与历史状态无关;当 αt 增加时，xt 变为高斯噪声：</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/34vCptz8Do7xlcM.png" alt="image.png"></p>
<p><img src="https://s2.loli.net/2025/02/14/tQlPdF3OhxY9nTW.png" alt="image.png"></p>
<h2 id="Inverse-Process"><a href="#Inverse-Process" class="headerlink" title="Inverse Process"></a>Inverse Process</h2><ul>
<li><p>目标：估计q(xt−1|xt)当 T 很大时，假设它是高斯的</p>
</li>
<li><p>关键观察：q(xt−1|xt，x0)也是高斯的</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2025/02/14/UMTuwbJAniIog4V.png" alt="image.png"></p>
<p><img src="https://s2.loli.net/2025/02/14/zFkI1c8eAJDhm2q.png" alt="image.png"></p>
<ul>
<li>Diffusion Models(DDPM):</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiffusionModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_size, channels, num_timesteps, betas=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DiffusionModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.image_size = image_size</span><br><span class="line">        <span class="variable language_">self</span>.channels = channels</span><br><span class="line">        <span class="variable language_">self</span>.num_timesteps = num_timesteps</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成beta值（也可以使用其他调度策略）</span></span><br><span class="line">        <span class="keyword">if</span> betas <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>.betas = torch.linspace(<span class="number">1e-4</span>, <span class="number">0.02</span>, num_timesteps)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.betas = betas</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向过程的参数（可以使用一个神经网络来建模）</span></span><br><span class="line">        <span class="variable language_">self</span>.network = nn.Sequential(</span><br><span class="line">            nn.Conv2d(channels, <span class="number">64</span>, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, channels, <span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_0, noise_schedule=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        x_0: 初始图像</span></span><br><span class="line"><span class="string">        noise_schedule: 噪声调度器（如果有自定义噪声调度）</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 通过正向扩散过程生成中间噪声图像</span></span><br><span class="line">        batch_size = x_0.size(<span class="number">0</span>)</span><br><span class="line">        device = x_0.device</span><br><span class="line">        x_t = x_0</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果有自定义噪声调度，则使用自定义的betas</span></span><br><span class="line">        betas = <span class="variable language_">self</span>.betas <span class="keyword">if</span> noise_schedule <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> noise_schedule</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_timesteps):</span><br><span class="line">            noise = torch.randn_like(x_t)</span><br><span class="line">            sqrt_alpha_t = torch.sqrt(<span class="number">1</span> - betas[t])</span><br><span class="line">            sqrt_beta_t = torch.sqrt(betas[t])</span><br><span class="line">            x_t = sqrt_alpha_t * x_t + sqrt_beta_t * noise  <span class="comment"># 正向过程</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x_t</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverse_process</span>(<span class="params">self, x_t, t, noise=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        反向过程，给定时刻t的图像x_t，生成一个去噪的图像</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> noise <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            noise = torch.randn_like(x_t)</span><br><span class="line">        </span><br><span class="line">        model_output = <span class="variable language_">self</span>.network(x_t)</span><br><span class="line">        x_0 = model_output  <span class="comment"># 基于网络输出的去噪图像</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x_0</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_diffusion_model</span>(<span class="params">model, dataloader, optimizer, num_epochs=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> batch_idx, (images, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">            images = images.to(device)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 获取正向过程生成的图像</span></span><br><span class="line">            noisy_images = model(images)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 使用模型预测噪声并计算损失</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss = F.mse_loss(noisy_images, images)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>, Batch <span class="subst">&#123;batch_idx&#125;</span>, Loss: <span class="subst">&#123;loss.item()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_from_diffusion</span>(<span class="params">model, shape=(<span class="params"><span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span></span>), num_timesteps=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># 从噪声开始生成图像</span></span><br><span class="line">    x_t = torch.randn(shape).to(device)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(num_timesteps)):</span><br><span class="line">        <span class="comment"># 进行反向过程</span></span><br><span class="line">        x_t = model.reverse_process(x_t, t)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x_t</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：假设你有一个数据集DataLoader</span></span><br><span class="line">dataloader = ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = DiffusionModel(image_size=<span class="number">32</span>, channels=<span class="number">3</span>, num_timesteps=<span class="number">1000</span>).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置优化器</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">train_diffusion_model(model, dataloader, optimizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从模型中采样</span></span><br><span class="line">generated_images = sample_from_diffusion(model, shape=(<span class="number">16</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br></pre></td></tr></table></figure>

<h2 id="DDPM-2020"><a href="#DDPM-2020" class="headerlink" title="DDPM 2020"></a>DDPM 2020</h2><p><img src="https://s2.loli.net/2025/02/14/nrGihFWp5xYZMtT.png" alt="image.png"></p>
<h2 id="DALL·E-2022"><a href="#DALL·E-2022" class="headerlink" title="DALL·E 2022"></a>DALL·E 2022</h2><p><img src="https://s2.loli.net/2025/02/14/XVvSK3PsEFLRYhC.png" alt="image.png"></p>
<h2 id="Stable-Diffusion-2022"><a href="#Stable-Diffusion-2022" class="headerlink" title="Stable Diffusion 2022"></a>Stable Diffusion 2022</h2><p><img src="https://s2.loli.net/2025/02/14/M97KxbwhrITsXFG.png" alt="image.png"></p>
<hr>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/post/30f06d20.html" title="DeepSeek-R1:Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"><img class="cover" src="https://s2.loli.net/2025/02/21/D6Cb5LuMrkVQeiz.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">DeepSeek-R1:Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</div></div></a></div><div class="next-post pull-right"><a href="/post/4ff2381f.html" title="计算机视觉 21 Image Segmentation"><img class="cover" src="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next</div><div class="next_info">计算机视觉 21 Image Segmentation</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/post/80c4a451.html" title="计算机视觉 02 Image Formation"><img class="cover" src="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-18</div><div class="title">计算机视觉 02 Image Formation</div></div></a></div><div><a href="/post/204c5630.html" title="计算机视觉 03 Image Processing"><img class="cover" src="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-18</div><div class="title">计算机视觉 03 Image Processing</div></div></a></div><div><a href="/post/e6fed564.html" title="计算机视觉 04 Feature Detection"><img class="cover" src="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-19</div><div class="title">计算机视觉 04 Feature Detection</div></div></a></div><div><a href="/post/26185b9c.html" title="计算机视觉 05 Image Stitching"><img class="cover" src="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-19</div><div class="title">计算机视觉 05 Image Stitching</div></div></a></div><div><a href="/post/80ee00fd.html" title="计算机视觉 06 3D Vision and Camera Calibration"><img class="cover" src="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-20</div><div class="title">计算机视觉 06 3D Vision and Camera Calibration</div></div></a></div><div><a href="/post/df1a2548.html" title="计算机视觉 07 Epipolar Geometry"><img class="cover" src="https://s2.loli.net/2024/11/18/zAG9fYxh35LIWK2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-27</div><div class="title">计算机视觉 07 Epipolar Geometry</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2024/07/16/lsEXfWtGT6eRu7k.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">w434</div><div class="author-info__description">An undergraduate majoring in AI at PKU.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">88</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">30</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/w434"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/w434" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Welcom to my blog.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B-Autoregressive-Models"><span class="toc-number">1.</span> <span class="toc-text">自回归模型(Autoregressive Models)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%98%BE%E5%BC%8F%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1-Explicit-Density-Estimation-Autoregressive-Models"><span class="toc-number">1.1.</span> <span class="toc-text">显式概率密度估计(Explicit Density Estimation: Autoregressive Models)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PixelCNN-and-PixelRNN"><span class="toc-number">1.2.</span> <span class="toc-text">PixelCNN and PixelRNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generative-Pretraining-from-Pixels"><span class="toc-number">1.3.</span> <span class="toc-text">Generative Pretraining from Pixels</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8-Variational-Autoencoder"><span class="toc-number">2.</span> <span class="toc-text">变分自编码器(Variational Autoencoder)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Autoencoder"><span class="toc-number">2.1.</span> <span class="toc-text">Autoencoder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Autoencoder-is-not-a-Generative-Model"><span class="toc-number">2.2.</span> <span class="toc-text">Autoencoder is not a Generative Model</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Generative-Adversarial-Network-GAN"><span class="toc-number">3.</span> <span class="toc-text">Generative Adversarial Network(GAN)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Generator-of-DCGAN"><span class="toc-number">3.1.</span> <span class="toc-text">The Generator of DCGAN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#StyleGAN"><span class="toc-number">3.2.</span> <span class="toc-text">StyleGAN</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Diffusion-Models"><span class="toc-number">4.</span> <span class="toc-text">Diffusion Models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Forward-Process"><span class="toc-number">4.1.</span> <span class="toc-text">Forward Process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inverse-Process"><span class="toc-number">4.2.</span> <span class="toc-text">Inverse Process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DDPM-2020"><span class="toc-number">4.3.</span> <span class="toc-text">DDPM 2020</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DALL%C2%B7E-2022"><span class="toc-number">4.4.</span> <span class="toc-text">DALL·E 2022</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Stable-Diffusion-2022"><span class="toc-number">4.5.</span> <span class="toc-text">Stable Diffusion 2022</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/1c1af71d.html" title="LLaMA1 自学笔记"><img src="https://s2.loli.net/2025/03/07/u2SEqVOMvexjFKJ.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLaMA1 自学笔记"/></a><div class="content"><a class="title" href="/post/1c1af71d.html" title="LLaMA1 自学笔记">LLaMA1 自学笔记</a><time datetime="2025-03-07T04:29:00.000Z" title="Created 2025-03-07 12:29:00">2025-03-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/139c00ec.html" title="大模型基础与对齐 02 Transformer &amp; GPT-3"><img src="https://s2.loli.net/2025/02/22/Od6DiNyG73wULja.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型基础与对齐 02 Transformer &amp; GPT-3"/></a><div class="content"><a class="title" href="/post/139c00ec.html" title="大模型基础与对齐 02 Transformer &amp; GPT-3">大模型基础与对齐 02 Transformer &amp; GPT-3</a><time datetime="2025-03-05T06:39:00.000Z" title="Created 2025-03-05 14:39:00">2025-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/b801ffcc.html" title="Learning PyTorch with Examples 自学笔记"><img src="https://s2.loli.net/2024/09/30/C7lO2rZFBpEjMRX.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Learning PyTorch with Examples 自学笔记"/></a><div class="content"><a class="title" href="/post/b801ffcc.html" title="Learning PyTorch with Examples 自学笔记">Learning PyTorch with Examples 自学笔记</a><time datetime="2025-03-04T05:53:00.000Z" title="Created 2025-03-04 13:53:00">2025-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/9ffc0448.html" title="Janus-Pro:Unified Multimodal Understanding and Generation with Data and Model Scaling"><img src="https://s2.loli.net/2025/02/22/PtwTxgJ8dYWh2IZ.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Janus-Pro:Unified Multimodal Understanding and Generation with Data and Model Scaling"/></a><div class="content"><a class="title" href="/post/9ffc0448.html" title="Janus-Pro:Unified Multimodal Understanding and Generation with Data and Model Scaling">Janus-Pro:Unified Multimodal Understanding and Generation with Data and Model Scaling</a><time datetime="2025-02-23T05:55:00.000Z" title="Created 2025-02-23 13:55:00">2025-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/6ccd62c9.html" title="大模型基础与对齐 01 LLM概述"><img src="https://s2.loli.net/2025/02/22/Od6DiNyG73wULja.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型基础与对齐 01 LLM概述"/></a><div class="content"><a class="title" href="/post/6ccd62c9.html" title="大模型基础与对齐 01 LLM概述">大模型基础与对齐 01 LLM概述</a><time datetime="2025-02-22T09:55:00.000Z" title="Created 2025-02-22 17:55:00">2025-02-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By w434</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcom to my blog.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional Chinese And Simplified Chinese">简</button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="/js/tw_cn.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>